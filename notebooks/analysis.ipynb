{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analysis Notebook for MCP-Attack Experiments\n",
        "#\n",
        "# This notebook loads Locust CSV outputs and MCP server metrics and\n",
        "# generates publication-ready plots (PNG) into notebooks/outputs/.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# Plot style\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "\n",
        "# Paths\n",
        "PROJECT_ROOT = Path(\"/app\") if Path(\"/app\").exists() else Path(\".\")\n",
        "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"notebooks\" / \"outputs\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"RESULTS_DIR={RESULTS_DIR}\")\n",
        "print(f\"OUTPUT_DIR={OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_experiments(base_dir: Path) -> list[Path]:\n",
        "    if not base_dir.exists():\n",
        "        return []\n",
        "    # experiment directory must contain at least one locust_stats_history.csv\n",
        "    candidates = []\n",
        "    for stats_hist in base_dir.glob(\"**/locust_stats_history.csv\"):\n",
        "        candidates.append(stats_hist.parent)\n",
        "    # include sample dirs that may only have mcp_metrics.csv\n",
        "    for m in base_dir.glob(\"**/mcp_metrics.csv\"):\n",
        "        if m.parent not in candidates:\n",
        "            candidates.append(m.parent)\n",
        "    # de-duplicate\n",
        "    out: list[Path] = []\n",
        "    for p in candidates:\n",
        "        if p not in out:\n",
        "            out.append(p)\n",
        "    return sorted(out)\n",
        "\n",
        "experiments = find_experiments(RESULTS_DIR)\n",
        "print(\"Found experiments:\")\n",
        "for p in experiments:\n",
        "    print(\" -\", p.relative_to(RESULTS_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_locust_history(exp_dir: Path) -> pd.DataFrame | None:\n",
        "    path = exp_dir / \"locust_stats_history.csv\"\n",
        "    if not path.exists():\n",
        "        return None\n",
        "    df = pd.read_csv(path)\n",
        "    # Normalize columns\n",
        "    # Common columns: Timestamp, Requests/s, Failures/s, 50%, 95%, 99%\n",
        "    rename_map = {}\n",
        "    for col in df.columns:\n",
        "        if col.lower().startswith(\"timestamp\"):\n",
        "            rename_map[col] = \"Timestamp\"\n",
        "        if col.lower().startswith(\"requests/s\"):\n",
        "            rename_map[col] = \"Requests/s\"\n",
        "        if col.lower().startswith(\"failures/s\"):\n",
        "            rename_map[col] = \"Failures/s\"\n",
        "        if col.strip() == \"50%\":\n",
        "            rename_map[col] = \"p50\"\n",
        "        if col.strip() == \"95%\":\n",
        "            rename_map[col] = \"p95\"\n",
        "        if col.strip() == \"99%\":\n",
        "            rename_map[col] = \"p99\"\n",
        "        if col.lower().startswith(\"average\") or col.strip() == \"Average\":\n",
        "            rename_map[col] = \"avg\"\n",
        "    df = df.rename(columns=rename_map)\n",
        "    # Keep only global rows if Type/Name columns exist\n",
        "    if \"Type\" in df.columns and \"Name\" in df.columns:\n",
        "        mask = (df[\"Type\"] == \"Aggregated\") & (df[\"Name\"] == \"All\")\n",
        "        if mask.any():\n",
        "            df = df[mask]\n",
        "    # Coerce types\n",
        "    for c in [\"Requests/s\", \"Failures/s\", \"p50\", \"p95\", \"p99\", \"avg\"]:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    # Add time index\n",
        "    if \"Timestamp\" in df.columns:\n",
        "        df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
        "        df = df.sort_values(\"Timestamp\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def read_cpu_mem(exp_dir: Path) -> pd.DataFrame | None:\n",
        "    path = exp_dir / \"cpu_mem.csv\"\n",
        "    if not path.exists():\n",
        "        return None\n",
        "    df = pd.read_csv(path)\n",
        "    if \"timestamp\" in df.columns:\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "        df = df.sort_values(\"timestamp\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def read_mcp_metrics(exp_dir: Path) -> pd.DataFrame | None:\n",
        "    path = exp_dir / \"mcp_metrics.csv\"\n",
        "    if not path.exists():\n",
        "        return None\n",
        "    df = pd.read_csv(path)\n",
        "    if \"timestamp\" in df.columns:\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "        df = df.sort_values(\"timestamp\")\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_rps_vs_latency(exp_dir: Path, df_hist: pd.DataFrame):\n",
        "    if df_hist is None or df_hist.empty:\n",
        "        print(f\"No stats_history for {exp_dir}\")\n",
        "        return\n",
        "    fig, ax1 = plt.subplots(figsize=(8, 4.5))\n",
        "    if \"Requests/s\" in df_hist.columns:\n",
        "        ax1.plot(df_hist[\"Timestamp\"], df_hist[\"Requests/s\"], label=\"RPS\", color=\"tab:blue\")\n",
        "        ax1.set_ylabel(\"RPS\", color=\"tab:blue\")\n",
        "        ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "    ax2 = ax1.twinx()\n",
        "    for col, label, color in [(\"p50\", \"p50\", \"tab:green\"), (\"p95\", \"p95\", \"tab:orange\"), (\"p99\", \"p99\", \"tab:red\")]:\n",
        "        if col in df_hist.columns:\n",
        "            ax2.plot(df_hist[\"Timestamp\"], df_hist[col], label=label, color=color, alpha=0.8)\n",
        "    ax2.set_ylabel(\"Latency (ms)\")\n",
        "    ax1.set_xlabel(\"Time\")\n",
        "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
        "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
        "    ax2.legend(lines_1 + lines_2, labels_1 + labels_2, loc=\"upper right\")\n",
        "    title = f\"RPS vs Latency — {exp_dir.relative_to(RESULTS_DIR)}\"\n",
        "    plt.title(title)\n",
        "    out = OUTPUT_DIR / f\"rps_vs_latency__{exp_dir.relative_to(RESULTS_DIR)}.png\"\n",
        "    out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out, dpi=150)\n",
        "    plt.close()\n",
        "    print(\"Saved\", out)\n",
        "\n",
        "\n",
        "def plot_latency_histogram(exp_dir: Path, df_mcp: pd.DataFrame):\n",
        "    if df_mcp is None or df_mcp.empty or \"latency_ms\" not in df_mcp.columns:\n",
        "        print(f\"No mcp_metrics for {exp_dir}\")\n",
        "        return\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    ax.hist(df_mcp[\"latency_ms\"].dropna(), bins=40, log=True, color=\"tab:purple\", alpha=0.8)\n",
        "    ax.set_xlabel(\"Latency (ms)\")\n",
        "    ax.set_ylabel(\"Frequency (log)\")\n",
        "    plt.title(f\"Latency Histogram — {exp_dir.relative_to(RESULTS_DIR)}\")\n",
        "    out = OUTPUT_DIR / f\"latency_hist__{exp_dir.relative_to(RESULTS_DIR)}.png\"\n",
        "    out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out, dpi=150)\n",
        "    plt.close()\n",
        "    print(\"Saved\", out)\n",
        "\n",
        "\n",
        "def plot_cpu_vs_failures(exp_dir: Path, df_cpu: pd.DataFrame, df_hist: pd.DataFrame):\n",
        "    if df_cpu is None or df_cpu.empty or df_hist is None or df_hist.empty:\n",
        "        print(f\"No cpu/failures data for {exp_dir}\")\n",
        "        return\n",
        "    # Resample to 1s and merge\n",
        "    c = df_cpu.copy()\n",
        "    c = c.set_index(pd.to_datetime(c[\"timestamp\"]))\n",
        "    c = c.resample(\"1s\").mean(numeric_only=True)\n",
        "    h = df_hist.copy()\n",
        "    h = h.set_index(pd.to_datetime(h[\"Timestamp\"]))\n",
        "    h = h.resample(\"1s\").mean(numeric_only=True)\n",
        "    dfm = c.join(h, how=\"inner\", lsuffix=\"_cpu\", rsuffix=\"_locust\")\n",
        "    fig, ax1 = plt.subplots(figsize=(8, 4.5))\n",
        "    if \"cpu_percent\" in dfm.columns:\n",
        "        ax1.plot(dfm.index, dfm[\"cpu_percent\"], color=\"tab:blue\", label=\"CPU %\")\n",
        "        ax1.set_ylabel(\"CPU %\", color=\"tab:blue\")\n",
        "        ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "    ax2 = ax1.twinx()\n",
        "    if \"Failures/s\" in dfm.columns:\n",
        "        ax2.plot(dfm.index, dfm[\"Failures/s\"], color=\"tab:red\", label=\"Failures/s\", alpha=0.7)\n",
        "    ax1.set_xlabel(\"Time\")\n",
        "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
        "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
        "    ax2.legend(lines_1 + lines_2, labels_1 + labels_2, loc=\"upper right\")\n",
        "    plt.title(f\"CPU% vs Failures/s — {exp_dir.relative_to(RESULTS_DIR)}\")\n",
        "    out = OUTPUT_DIR / f\"cpu_vs_failures__{exp_dir.relative_to(RESULTS_DIR)}.png\"\n",
        "    out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out, dpi=150)\n",
        "    plt.close()\n",
        "    print(\"Saved\", out)\n",
        "\n",
        "\n",
        "def plot_cachehit_vs_latency(exp_dir: Path, df_mcp: pd.DataFrame):\n",
        "    if df_mcp is None or df_mcp.empty or \"cache_hit\" not in df_mcp.columns:\n",
        "        print(f\"No cache_hit metric for {exp_dir}\")\n",
        "        return\n",
        "    # group by cache_hit and plot boxplot of latency\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    df_mcp.boxplot(column=\"latency_ms\", by=\"cache_hit\", ax=ax)\n",
        "    ax.set_xlabel(\"cache_hit (0/1)\")\n",
        "    ax.set_ylabel(\"Latency (ms)\")\n",
        "    plt.suptitle(\"\")\n",
        "    plt.title(f\"Cache-hit vs Latency — {exp_dir.relative_to(RESULTS_DIR)}\")\n",
        "    out = OUTPUT_DIR / f\"cachehit_vs_latency__{exp_dir.relative_to(RESULTS_DIR)}.png\"\n",
        "    out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out, dpi=150)\n",
        "    plt.close()\n",
        "    print(\"Saved\", out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run plots for all discovered experiments\n",
        "for exp in experiments:\n",
        "    df_hist = read_locust_history(exp)\n",
        "    df_cpu = read_cpu_mem(exp)\n",
        "    df_mcp = read_mcp_metrics(exp)\n",
        "    plot_rps_vs_latency(exp, df_hist)\n",
        "    plot_latency_histogram(exp, df_mcp)\n",
        "    plot_cpu_vs_failures(exp, df_cpu, df_hist)\n",
        "    plot_cachehit_vs_latency(exp, df_mcp)\n",
        "\n",
        "print(\"Done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def read_locust_stats(exp_dir: Path) -> pd.DataFrame | None:\n",
        "    path = exp_dir / \"locust_stats.csv\"\n",
        "    if not path.exists():\n",
        "        return None\n",
        "    df = pd.read_csv(path)\n",
        "    # Normalize and filter request rows\n",
        "    rename_map = {}\n",
        "    if \"95%\" in df.columns:\n",
        "        rename_map[\"95%\"] = \"p95\"\n",
        "    if \"50%\" in df.columns:\n",
        "        rename_map[\"50%\"] = \"p50\"\n",
        "    if \"Average\" in df.columns:\n",
        "        rename_map[\"Average\"] = \"avg\"\n",
        "    df = df.rename(columns=rename_map)\n",
        "    if \"Type\" in df.columns:\n",
        "        df = df[df[\"Type\"] == \"Request\"]\n",
        "    return df\n",
        "\n",
        "\n",
        "def summarize_validate_p95(exp_dirs: list[Path]) -> pd.DataFrame:\n",
        "    rows: list[dict] = []\n",
        "    pattern = re.compile(r\"validate_(\\d+)B_d(\\d+)\")\n",
        "    for exp_dir in exp_dirs:\n",
        "        df = read_locust_stats(exp_dir)\n",
        "        if df is None or df.empty:\n",
        "            continue\n",
        "        for _, r in df.iterrows():\n",
        "            name = str(r.get(\"Name\", \"\"))\n",
        "            m = pattern.search(name)\n",
        "            if not m:\n",
        "                continue\n",
        "            size = int(m.group(1))\n",
        "            depth = int(m.group(2))\n",
        "            p95_val = r.get(\"p95\", r.get(\"95%\", None))\n",
        "            try:\n",
        "                p95 = float(p95_val)\n",
        "            except Exception:\n",
        "                continue\n",
        "            rows.append({\n",
        "                \"experiment\": exp_dir.relative_to(RESULTS_DIR).as_posix(),\n",
        "                \"size_bytes\": size,\n",
        "                \"depth\": depth,\n",
        "                \"p95\": p95,\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def plot_payload_p95_bars(df: pd.DataFrame):\n",
        "    if df is None or df.empty:\n",
        "        print(\"No payload p95 data to plot\")\n",
        "        return\n",
        "    pivot = df.pivot_table(index=\"size_bytes\", columns=\"depth\", values=\"p95\", aggfunc=\"mean\").sort_index()\n",
        "    ax = pivot.plot(kind=\"bar\", figsize=(8, 4.5))\n",
        "    ax.set_xlabel(\"Payload size (bytes)\")\n",
        "    ax.set_ylabel(\"p95 latency (ms)\")\n",
        "    ax.set_title(\"Payload size/depth vs p95 (bar)\")\n",
        "    out = OUTPUT_DIR / \"payload_p95__combined.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out, dpi=150)\n",
        "    plt.close()\n",
        "    print(\"Saved\", out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build payload p95 bar chart across experiments\n",
        "val_dirs = [p for p in experiments if any(\"validate\" in (f.name) for f in p.iterdir())]\n",
        "summary_df = summarize_validate_p95(val_dirs)\n",
        "plot_payload_p95_bars(summary_df)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
